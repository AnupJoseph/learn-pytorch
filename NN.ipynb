{"cells":[{"cell_type":"code","metadata":{"tags":[],"cell_id":"fc6f6b54-75e4-47e8-b33d-28f75d65fcc3"},"source":"import torch\r\nimport torch.nn as nn\r\nimport torchvision.transforms as transforms\r\nimport torchvision.datasets as datasets","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"03034c6c-d4cf-43fd-afa1-b1ecc42f6cf2"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"2b2e3247-3c75-4374-ba28-0a3edbc9f9e9"},"source":"batch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e64b9c8c-61dd-47f0-9473-695b5a53daff"},"source":"class FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.sigmoid = nn.Sigmoid()\r\n        self.fc2 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.sigmoid(out)\r\n        out = self.fc2(out)\r\n        return out\r\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"b1a415e5-7061-427a-8127-8c9ff210e2a8"},"source":"input_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"e00e71ed-2e6f-48b6-86cf-d172badc5341"},"source":"criterion = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"c5e12b60-d5c2-4d0f-ba60-64bb4ee7c0a8"},"source":"learning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"fc83752a-d857-462c-b5f2-573bb477452f"},"source":"iter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_()\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_()\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stderr","text":"/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\nIteration: 500. Loss: 0.4963933527469635. Accuracy: 86\nIteration: 1000. Loss: 0.3637200891971588. Accuracy: 89\nIteration: 1500. Loss: 0.29671013355255127. Accuracy: 90\nIteration: 2000. Loss: 0.2967323362827301. Accuracy: 91\nIteration: 2500. Loss: 0.2763761281967163. Accuracy: 91\nIteration: 3000. Loss: 0.5291683673858643. Accuracy: 92\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"579e4946-0c5b-4105-91bf-ba033105fee9"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\r\n\r\nbatch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\r\n\r\nclass FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.tanh = nn.Tanh()\r\n        self.fc2 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.tanh(out)\r\n        out = self.fc2(out)\r\n        return out\r\n\r\ninput_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\nlearning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)\r\n\r\niter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_()\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_()\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss: 0.5495707988739014. Accuracy: 91\nIteration: 1000. Loss: 0.2172483503818512. Accuracy: 92\nIteration: 1500. Loss: 0.16044455766677856. Accuracy: 93\nIteration: 2000. Loss: 0.2312755435705185. Accuracy: 93\nIteration: 2500. Loss: 0.21641124784946442. Accuracy: 94\nIteration: 3000. Loss: 0.1174468919634819. Accuracy: 95\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"677a9da1-8878-440e-83a5-e2feebbe0e51"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\r\n\r\nbatch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\r\n\r\nclass FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.relu = nn.ReLU()\r\n        self.fc2 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.relu(out)\r\n        out = self.fc2(out)\r\n        return out\r\n\r\ninput_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\nlearning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)\r\n\r\niter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_()\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_()\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss: 0.41141125559806824. Accuracy: 91\nIteration: 1000. Loss: 0.19843018054962158. Accuracy: 92\nIteration: 1500. Loss: 0.20181341469287872. Accuracy: 94\nIteration: 2000. Loss: 0.17491742968559265. Accuracy: 94\nIteration: 2500. Loss: 0.1918606162071228. Accuracy: 95\nIteration: 3000. Loss: 0.24881862103939056. Accuracy: 95\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"9c68ca39-d5a1-4ce4-b338-7e909fbf903b"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\r\n\r\nbatch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\r\n\r\nclass FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.relu1 = nn.ReLU()\r\n        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n\r\n        self.relu2 = nn.ReLU()\r\n        self.fc3 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.relu1(out)\r\n        out = self.fc2(out)\r\n        out = self.relu2(out)\r\n        out = self.fc3(out)\r\n        return out\r\n\r\ninput_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\nlearning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)\r\n\r\niter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_()\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_()\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss: 0.4337555766105652. Accuracy: 91\nIteration: 1000. Loss: 0.16706930100917816. Accuracy: 93\nIteration: 1500. Loss: 0.2003202885389328. Accuracy: 94\nIteration: 2000. Loss: 0.07536744326353073. Accuracy: 95\nIteration: 2500. Loss: 0.1584356129169464. Accuracy: 96\nIteration: 3000. Loss: 0.17269065976142883. Accuracy: 96\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"5f074563-16a1-4a21-a241-5a2584d16de2"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\r\n\r\nbatch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\r\n\r\nclass FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.relu1 = nn.ReLU()\r\n        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n\r\n        self.relu2 = nn.ReLU()\r\n        self.fc3 = nn.Linear(hidden_dim,hidden_dim)\r\n\r\n        self.relu3 = nn.ReLU()\r\n        self.fc4 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.relu1(out)\r\n        out = self.fc2(out)\r\n        out = self.relu2(out)\r\n        out = self.fc3(out)\r\n        out = self.relu3(out)\r\n        out = self.fc4(out)\r\n        return out\r\n\r\ninput_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\nlearning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)\r\n\r\niter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_()\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_()\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss: 0.33805596828460693. Accuracy: 91\nIteration: 1000. Loss: 0.3607591688632965. Accuracy: 93\nIteration: 1500. Loss: 0.13835036754608154. Accuracy: 95\nIteration: 2000. Loss: 0.053997211158275604. Accuracy: 96\nIteration: 2500. Loss: 0.09074047952890396. Accuracy: 96\nIteration: 3000. Loss: 0.0835341066122055. Accuracy: 96\n","output_type":"stream"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"0a3b19bc-286d-4326-b2b3-24daff5aab53"},"source":"train_dataset = datasets.MNIST(root='./data',transform=transforms.ToTensor(),download=True)\r\ntest_dataset = datasets.MNIST(root='./data',train=False,transform=transforms.ToTensor())\r\n\r\nbatch_size,n_iters = 100,3000\r\nnum_epochs = int(n_iters/(len(train_dataset)/batch_size))\r\n\r\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,shuffle=True)\r\ntest_loader = torch.utils.data.DataLoader(dataset=test_dataset,batch_size=batch_size,shuffle=False)\r\n\r\nclass FeedForwardNeuralNetwork(nn.Module):\r\n    def __init__(self,input_dim, hidden_dim, output_dim):\r\n        super(FeedForwardNeuralNetwork,self).__init__()\r\n\r\n        self.fc1 = nn.Linear(input_dim,hidden_dim)\r\n\r\n        self.relu1 = nn.ReLU()\r\n        self.fc2 = nn.Linear(hidden_dim,hidden_dim)\r\n\r\n        self.relu2 = nn.ReLU()\r\n        self.fc3 = nn.Linear(hidden_dim,hidden_dim)\r\n\r\n        self.relu3 = nn.ReLU()\r\n        self.fc4 = nn.Linear(hidden_dim,output_dim)\r\n\r\n    def forward(self,x):\r\n        out = self.fc1(x)\r\n        out = self.relu1(out)\r\n        out = self.fc2(out)\r\n        out = self.relu2(out)\r\n        out = self.fc3(out)\r\n        out = self.relu3(out)\r\n        out = self.fc4(out)\r\n        return out\r\n\r\ninput_dim = 28**2\r\nhidden_dim = 100\r\noutput_dim = 10\r\nmodel = FeedForwardNeuralNetwork(input_dim=input_dim,hidden_dim=hidden_dim,output_dim=output_dim)\r\n\r\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\nmodel.to(device)\r\n\r\ncriterion = nn.CrossEntropyLoss()\r\nlearning_Rate = 0.1\r\noptimizer = torch.optim.SGD(model.parameters(),lr=learning_Rate)\r\n\r\n\r\niter = 0\r\nfor epoch in range(num_epochs):\r\n    for i, (images, labels) in enumerate(train_loader):\r\n        # Load images with gradient accumulation capabilities\r\n        images = images.view(-1, 28*28).requires_grad_().to(device)\r\n        labels = labels.to(device)\r\n\r\n        # Clear gradients w.r.t. parameters\r\n        optimizer.zero_grad()\r\n\r\n        # Forward pass to get output/logits\r\n        outputs = model(images)\r\n\r\n        # Calculate Loss: softmax --> cross entropy loss\r\n        loss = criterion(outputs, labels)\r\n\r\n        # Getting gradients w.r.t. parameters\r\n        loss.backward()\r\n\r\n        # Updating parameters\r\n        optimizer.step()\r\n\r\n        iter += 1\r\n\r\n        if iter % 500 == 0:\r\n            # Calculate Accuracy         \r\n            correct = 0\r\n            total = 0\r\n            # Iterate through test dataset\r\n            for images, labels in test_loader:\r\n                # Load images with gradient accumulation capabilities\r\n                images = images.view(-1, 28*28).requires_grad_().to(device)\r\n\r\n                # Forward pass only to get logits/output\r\n                outputs = model(images)\r\n\r\n                # Get predictions from the maximum value\r\n                _, predicted = torch.max(outputs.data, 1)\r\n\r\n                # Total number of labels\r\n                total += labels.size(0)\r\n\r\n                # Total correct predictions\r\n                if torch.cuda.is_available():\r\n                    correct += (predicted.cpu() == labels.cpu()).sum()\r\n                else:\r\n                    correct += (predicted == labels).sum()\r\n\r\n            accuracy = 100 * correct / total\r\n\r\n            # Print Loss\r\n            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))","execution_count":null,"outputs":[{"name":"stdout","text":"Iteration: 500. Loss: 0.3662842810153961. Accuracy: 90\nIteration: 1000. Loss: 0.1286233365535736. Accuracy: 93\nIteration: 1500. Loss: 0.2579042911529541. Accuracy: 95\nIteration: 2000. Loss: 0.08410173654556274. Accuracy: 96\nIteration: 2500. Loss: 0.0626690611243248. Accuracy: 96\nIteration: 3000. Loss: 0.11885710805654526. Accuracy: 96\n","output_type":"stream"}]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"cf931be4-a60e-4921-b55e-519d27eae022","deepnote_execution_queue":[]}}